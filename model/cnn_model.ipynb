{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as Fn\n",
    "from torch import optim\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNArchitecture(nn.Module):\n",
    "\n",
    "    def __init__(self, classes):\n",
    "        super(CNNArchitecture, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.Pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(256 , 256)  # Adjusted for the output size after pooling\n",
    "        # self.fc2 = nn.Linear(1024, 512)\n",
    "        # self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        # self.fc5 = nn.Linear(128, 64)\n",
    "        self.fc6 = nn.Linear(128, classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Convolutional layers with ReLU activations and pooling\n",
    "        x = Fn.relu(self.conv1(x))\n",
    "        x = self.Pool(x)\n",
    "        x = Fn.relu(self.conv2(x))\n",
    "        x = self.Pool(x)\n",
    "        x = Fn.relu(self.conv3(x))\n",
    "        x = self.Pool(x)\n",
    "        x = Fn.relu(self.conv4(x))\n",
    "        x = self.Pool(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)  # Flatten the output to (batch_size, num_features)\n",
    "        # print(x.shape)\n",
    "\n",
    "        # Fully connected layers with ReLU activations\n",
    "        x = Fn.relu(self.fc1(x))\n",
    "        x = Fn.relu(self.fc2(x))\n",
    "        x = Fn.relu(self.fc3(x))\n",
    "        x = Fn.relu(self.fc4(x))\n",
    "        x = Fn.relu(self.fc5(x))\n",
    "\n",
    "        # Final output layer (no ReLU)\n",
    "        x = self.fc6(x)\n",
    "        # print(x.shape)\n",
    "        # out = torch.argmax(x, dim=1).float()\n",
    "        # print(out)\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed collecting all the data points X: (23932, 128, 173) and Y: (23932,)\n",
      " Mean of DataPoints: [[[-0.2380136]]] and STD of DataPoints: [[[0.07312169]]]\n"
     ]
    }
   ],
   "source": [
    "import data_loader #import getDatapoints\n",
    "\n",
    "trainDataLoader, testDataLoader = data_loader.getDatapoints()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.1053, Accuracy: 95.0367%\n",
      "Epoch 2/10, Loss: 0.4029, Accuracy: 91.8609%\n",
      "Epoch 3/10, Loss: 0.0000, Accuracy: 100.0000%\n",
      "Stopping the Training as Accuracy has reached to Maximum\n",
      "Model saved to Model Path\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "epochs = 10\n",
    "model = CNNArchitecture(classes=6)\n",
    "\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True \n",
    "lossFn = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "for each_epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    correct_predictions = 0 \n",
    "    total_samples = 0\n",
    "\n",
    "    for batch_id, (trainX, trainY) in enumerate(trainDataLoader):\n",
    "        \n",
    "        start_time = time.time()\n",
    "\n",
    "        # Add channel dimension (for Conv2d)\n",
    "        trainX = trainX.unsqueeze(1)  # Adds a channel dimension at position 1\n",
    "        trainX = trainX.to(device)\n",
    "        trainY = trainY.long()\n",
    "        trainY = trainY.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        pred = model(trainX)\n",
    "        \n",
    "        # print(\"Predictions dtype:\", pred.dtype)  # This should be torch.float32\n",
    "        # trainY.dtype = torch.long()\n",
    "        # print(\"Targets dtype:\", trainY.dtype) \n",
    "        # Compute the loss\n",
    "        lossval = lossFn(pred, trainY)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Check if the loss tensor requires gradients\n",
    "        # print(\"Check: \", lossval.requires_grad)  # This should print True now\n",
    "\n",
    "        # Backward pass\n",
    "        lossval.backward()\n",
    "\n",
    "        # Update model parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += lossval.item()  # Add batch loss to epoch loss\n",
    "        \n",
    "        end_time = time.time()\n",
    "        batch_time = end_time - start_time  # Time taken for the batch\n",
    "        # print(f\"Batch {batch_id + 1}, Time per batch: {batch_time:.4f} seconds\")\n",
    "\n",
    "        # break  # For debugging, you can remove this to train on the full dataset\n",
    "        with torch.no_grad():  # No gradient computation for accuracy\n",
    "            predictions = torch.argmax(pred, dim=1)  # Get predicted class labels\n",
    "            correct_predictions += (predictions == trainY).sum().item()  # Count correct predictions\n",
    "            total_samples += trainY.size(0)  # Update total number of samples\n",
    "    average_loss = epoch_loss / len(trainDataLoader)  # Average loss\n",
    "    accuracy = correct_predictions / total_samples * 100  # Accuracy as percentage\n",
    "\n",
    "    # Display metrics for the epoch\n",
    "    print(f\"Epoch {each_epoch + 1}/{epochs}, Loss: {average_loss:.4f}, Accuracy: {accuracy:.4f}%\")\n",
    "\n",
    "    if(accuracy >= 99):\n",
    "        print(f\"Stopping the Training as Accuracy has reached to Maximum\")\n",
    "        break\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "torch.save(model.state_dict(), f = \"/Users/ishananand/Desktop/ser/Speech-Emotion-Recognition/model_weight/CNNModel.pth\")\n",
    "print(f\"Model saved to Model Path\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training without Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed collecting all the data points X: (23932, 128, 173) and Y: (23932,)\n",
      "21538 2394\n",
      "Completed collecting all the data points X: (23932, 128, 173) and Y: (23932,)\n",
      "Epoch 1/10, Loss: 0.2776, Accuracy: 87.3572%\n",
      "Epoch 2/10, Loss: 0.0000, Accuracy: 100.0000%\n",
      "Stopping the Training as Accuracy has reached to Maximum\n",
      "Model saved to Model Path\n"
     ]
    }
   ],
   "source": [
    "import data_loader #import getDatapoints\n",
    "\n",
    "trainDataLoader, testDataLoader = data_loader.getDatapoints()\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "epochs = 10\n",
    "model = CNNArchitecture(classes=6)\n",
    "\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True \n",
    "lossFn = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "for each_epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    correct_predictions = 0 \n",
    "    total_samples = 0\n",
    "\n",
    "    for batch_id, (trainX, trainY) in enumerate(trainDataLoader):\n",
    "        \n",
    "        start_time = time.time()\n",
    "\n",
    "        # Add channel dimension (for Conv2d)\n",
    "        trainX = trainX.unsqueeze(1)  # Adds a channel dimension at position 1\n",
    "        trainX = trainX.to(device)\n",
    "        trainY = trainY.long()\n",
    "        trainY = trainY.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        pred = model(trainX)\n",
    "        \n",
    "        # print(\"Predictions dtype:\", pred.dtype)  # This should be torch.float32\n",
    "        # trainY.dtype = torch.long()\n",
    "        # print(\"Targets dtype:\", trainY.dtype) \n",
    "        # Compute the loss\n",
    "        lossval = lossFn(pred, trainY)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Check if the loss tensor requires gradients\n",
    "        # print(\"Check: \", lossval.requires_grad)  # This should print True now\n",
    "\n",
    "        # Backward pass\n",
    "        lossval.backward()\n",
    "\n",
    "        # Update model parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += lossval.item()  # Add batch loss to epoch loss\n",
    "        \n",
    "        end_time = time.time()\n",
    "        batch_time = end_time - start_time  # Time taken for the batch\n",
    "        # print(f\"Batch {batch_id + 1}, Time per batch: {batch_time:.4f} seconds\")\n",
    "\n",
    "        # break  # For debugging, you can remove this to train on the full dataset\n",
    "        with torch.no_grad():  # No gradient computation for accuracy\n",
    "            predictions = torch.argmax(pred, dim=1)  # Get predicted class labels\n",
    "            correct_predictions += (predictions == trainY).sum().item()  # Count correct predictions\n",
    "            total_samples += trainY.size(0)  # Update total number of samples\n",
    "    average_loss = epoch_loss / len(trainDataLoader)  # Average loss\n",
    "    accuracy = correct_predictions / total_samples * 100  # Accuracy as percentage\n",
    "\n",
    "    # Display metrics for the epoch\n",
    "    print(f\"Epoch {each_epoch + 1}/{epochs}, Loss: {average_loss:.4f}, Accuracy: {accuracy:.4f}%\")\n",
    "\n",
    "    if(accuracy >= 99):\n",
    "        print(f\"Stopping the Training as Accuracy has reached to Maximum\")\n",
    "        break\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "torch.save(model.state_dict(), f = \"/Users/ishananand/Desktop/ser/Speech-Emotion-Recognition/model_weight/CNNModel_NoNorm.pth\")\n",
    "print(f\"Model saved to Model Path\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNArchitecture2(nn.Module):\n",
    "\n",
    "    def __init__(self, classes):\n",
    "        super(CNNArchitecture2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.Pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(256 , 256)  # Adjusted for the output size after pooling\n",
    "        # self.fc2 = nn.Linear(1024, 512)\n",
    "        # self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        # self.fc5 = nn.Linear(128, 64)\n",
    "        self.fc6 = nn.Linear(128, classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Convolutional layers with ReLU activations and pooling\n",
    "        x = Fn.relu(self.conv1(x))\n",
    "        x = self.Pool(x)\n",
    "        x = Fn.relu(self.conv2(x))\n",
    "        x = self.Pool(x)\n",
    "        x = Fn.relu(self.conv3(x))\n",
    "        x = self.Pool(x)\n",
    "        x = Fn.relu(self.conv4(x))\n",
    "        x = self.Pool(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)  # Flatten the output to (batch_size, num_features)\n",
    "        # print(x.shape)\n",
    "\n",
    "        # Fully connected layers with ReLU activations\n",
    "        x = Fn.relu(self.fc1(x))\n",
    "        # x = Fn.relu(self.fc2(x))\n",
    "        # x = Fn.relu(self.fc3(x))\n",
    "        x = Fn.relu(self.fc4(x))\n",
    "        # x = Fn.relu(self.fc5(x))\n",
    "\n",
    "        # Final output layer (no ReLU)\n",
    "        x = self.fc6(x)\n",
    "        # print(x.shape)\n",
    "        # out = torch.argmax(x, dim=1).float()\n",
    "        # print(out)\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.1258, Accuracy: 95.2920%\n",
      "Epoch 2/10, Loss: 0.0000, Accuracy: 100.0000%\n",
      "Stopping the Training as Accuracy has reached to Maximum\n",
      "Model saved to Model Path\n"
     ]
    }
   ],
   "source": [
    "import data_loader #import getDatapoints\n",
    "\n",
    "# trainDataLoader, testDataLoader = data_loader.getDatapoints()\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "epochs = 10\n",
    "model = CNNArchitecture2(classes=6)\n",
    "\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True \n",
    "lossFn = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "for each_epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    correct_predictions = 0 \n",
    "    total_samples = 0\n",
    "\n",
    "    for batch_id, (trainX, trainY) in enumerate(trainDataLoader):\n",
    "        \n",
    "        start_time = time.time()\n",
    "\n",
    "        # Add channel dimension (for Conv2d)\n",
    "        trainX = trainX.unsqueeze(1)  # Adds a channel dimension at position 1\n",
    "        trainX = trainX.to(device)\n",
    "        trainY = trainY.long()\n",
    "        trainY = trainY.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        pred = model(trainX)\n",
    "        \n",
    "        # print(\"Predictions dtype:\", pred.dtype)  # This should be torch.float32\n",
    "        # trainY.dtype = torch.long()\n",
    "        # print(\"Targets dtype:\", trainY.dtype) \n",
    "        # Compute the loss\n",
    "        lossval = lossFn(pred, trainY)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Check if the loss tensor requires gradients\n",
    "        # print(\"Check: \", lossval.requires_grad)  # This should print True now\n",
    "\n",
    "        # Backward pass\n",
    "        lossval.backward()\n",
    "\n",
    "        # Update model parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += lossval.item()  # Add batch loss to epoch loss\n",
    "        \n",
    "        end_time = time.time()\n",
    "        batch_time = end_time - start_time  # Time taken for the batch\n",
    "        # print(f\"Batch {batch_id + 1}, Time per batch: {batch_time:.4f} seconds\")\n",
    "\n",
    "        # break  # For debugging, you can remove this to train on the full dataset\n",
    "        with torch.no_grad():  # No gradient computation for accuracy\n",
    "            predictions = torch.argmax(pred, dim=1)  # Get predicted class labels\n",
    "            correct_predictions += (predictions == trainY).sum().item()  # Count correct predictions\n",
    "            total_samples += trainY.size(0)  # Update total number of samples\n",
    "    average_loss = epoch_loss / len(trainDataLoader)  # Average loss\n",
    "    accuracy = correct_predictions / total_samples * 100  # Accuracy as percentage\n",
    "\n",
    "    # Display metrics for the epoch\n",
    "    print(f\"Epoch {each_epoch + 1}/{epochs}, Loss: {average_loss:.4f}, Accuracy: {accuracy:.4f}%\")\n",
    "\n",
    "    if(accuracy >= 99):\n",
    "        print(f\"Stopping the Training as Accuracy has reached to Maximum\")\n",
    "        break\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "torch.save(model.state_dict(), f = \"/Users/ishananand/Desktop/ser/Speech-Emotion-Recognition/model_weight/CNNModelBN.pth\")\n",
    "print(f\"Model saved to Model Path\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy is  100.0\n"
     ]
    }
   ],
   "source": [
    "test_model = CNNArchitecture2(classes=6)\n",
    "# Load the saved model weights\n",
    "# test_model.load_state_dict(torch.load('/Users/ishananand/Desktop/ser/Speech-Emotion-Recognition/model_weight/CNNModel_NoNorm.pth'))\n",
    "test_model.load_state_dict(torch.load('/Users/ishananand/Desktop/ser/Speech-Emotion-Recognition/model_weight/CNNModelBN.pth'))\n",
    "\n",
    "# Move the model to the appropriate device (CPU or GPU)\n",
    "# 5. Set the model to evaluation mode (important for inference)\n",
    "\n",
    "# the model to evaluation mode (important for inference)\n",
    "test_model.eval()\n",
    "\n",
    "def testAccuracy(model, loader):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "\n",
    "            x = x.unsqueeze(1)  # Adds a channel dimension at position 1\n",
    "            y = y.long()\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            scores = model(x)\n",
    "\n",
    "            predictions = torch.argmax(scores, dim=1)\n",
    "            # print(predictions, \"-----\", y)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "    model.train()\n",
    "    accuracy = num_correct / num_samples * 100  # Accuracy as percentage\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "testAccuracy = testAccuracy(test_model, testDataLoader)\n",
    "print(f\"Test Accuracy is  {testAccuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -1.3048,  10.3338,   4.9817,  12.7780, -19.9045,  -6.4331]])\n",
      "tensor([3]) ----- tensor([1])\n"
     ]
    }
   ],
   "source": [
    "from data_loader import getMelVector\n",
    "test_audio = getMelVector(\"/Users/ishananand/Desktop/ser/testAudios/angry.wav\", 4)\n",
    "X, Y = [], []\n",
    "X.append(test_audio)\n",
    "Y.append(1)\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "Y = Y.astype(np.int64)\n",
    "# X = (X - (-1 * 0.2380136)) / 0.07312169  # This normalization will use the same mean and std for all images\n",
    "X_tensor = torch.tensor(X)\n",
    "Y_tensor = torch.tensor(Y, dtype=torch.long)  # Use torch.float32 for regression, torch.long for classification\n",
    "\n",
    "dataset = TensorDataset(X_tensor, Y_tensor)\n",
    "customLoader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "# customLoader.dataset\n",
    "with torch.no_grad():\n",
    "    for x, y in customLoader:\n",
    "\n",
    "        x = x.unsqueeze(1)  # Adds a channel dimension at position 1\n",
    "        y = y.long()\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        scores = test_model(x)\n",
    "        print(scores)\n",
    "\n",
    "        predictions = torch.argmax(scores, dim=1)\n",
    "        print(predictions, \"-----\", y)\n",
    "\n",
    "    test_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ishananand/Desktop/ser/testAudios/happy.wav\n",
      "/Users/ishananand/Desktop/ser/testAudios/sad.wav\n",
      "/Users/ishananand/Desktop/ser/testAudios/sad_G.wav\n",
      "/Users/ishananand/Desktop/ser/testAudios/fear.wav\n",
      "/Users/ishananand/Desktop/ser/testAudios/angry.wav\n",
      "/Users/ishananand/Desktop/ser/testAudios/disgust.wav\n",
      "/Users/ishananand/Desktop/ser/testAudios/happy1.wav\n",
      "/Users/ishananand/Desktop/ser/testAudios/neutral1.wav\n",
      "tensor([[  2.3857,  10.6884,   1.6839,   9.5668, -17.5970,  -4.3711]])\n",
      "tensor([1]) ----- 0\n",
      "tensor([[  2.8608,   9.2331,   0.2235,  11.0609, -19.5865,  -3.7930]])\n",
      "tensor([3]) ----- 3\n",
      "tensor([[  2.0851,   7.0425,  -3.9147,  11.7141, -15.8335,   1.4583]])\n",
      "tensor([3]) ----- 3\n",
      "tensor([[ -0.2709,   9.5504,   4.4252,   9.8490, -16.2871,  -5.3582]])\n",
      "tensor([3]) ----- 2\n",
      "tensor([[  1.6054,  10.3512,   4.0008,   7.0067, -13.6818,  -4.9789]])\n",
      "tensor([1]) ----- 1\n",
      "tensor([[-0.7818, 11.3698,  6.9910,  4.9887, -9.1297, -5.5539]])\n",
      "tensor([1]) ----- 4\n",
      "tensor([[ 0.8191,  6.1445,  4.4944,  2.3692, -2.9502, -3.5335]])\n",
      "tensor([1]) ----- 0\n",
      "tensor([[-2.3585,  7.0657,  9.3935,  3.7029, -4.6950, -6.8296]])\n",
      "tensor([2]) ----- 5\n"
     ]
    }
   ],
   "source": [
    "from data_loader import getMelVector\n",
    "import os\n",
    "test_model.load_state_dict(torch.load('/Users/ishananand/Desktop/ser/Speech-Emotion-Recognition/model_weight/CNNModelBN.pth'))\n",
    "# test_model.load_state_dict(torch.load('/Users/ishananand/Desktop/ser/Speech-Emotion-Recognition/model_weight/CNNModel.pth'))\n",
    "\n",
    "allAudios = os.listdir(\"/Users/ishananand/Desktop/ser/testAudios\")\n",
    "rootpath = \"/Users/ishananand/Desktop/ser/testAudios\"\n",
    "emotion_class = {\n",
    "    0: \"happy\",\n",
    "    1: \"angry\",\n",
    "    2: \"fear\",\n",
    "    3: \"sad\",\n",
    "    4: \"disgust\",\n",
    "    5: \"neutral\"\n",
    "}\n",
    "X, Y = [], []\n",
    "for each_audio in allAudios:\n",
    "    print(rootpath + \"/\" +each_audio)\n",
    "\n",
    "    test_audio = getMelVector(rootpath + \"/\" +each_audio, 5)\n",
    "    # print(test_audio)\n",
    "    \n",
    "    X.append(test_audio)\n",
    "    if(\"angry\" in each_audio):\n",
    "        Y.append(1)\n",
    "    elif(\"disgust\" in each_audio):\n",
    "        Y.append(4)\n",
    "    elif(\"happy\" in each_audio):\n",
    "        Y.append(0)\n",
    "    elif(\"sad\" in each_audio):\n",
    "        Y.append(3)\n",
    "    elif(\"neutral\" in each_audio):\n",
    "        Y.append(5)\n",
    "    elif(\"fear\" in each_audio):\n",
    "        Y.append(2)\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "Y = Y.astype(np.int64)\n",
    "# X = (X - (-1 * 0.2380136)) / 0.07312169  # This normalization will use the same mean and std for all images\n",
    "X_tensor = torch.tensor(X)\n",
    "Y_tensor = torch.tensor(Y, dtype=torch.long)  # Use torch.float32 for regression, torch.long for classification\n",
    "\n",
    "dataset = TensorDataset(X_tensor, Y_tensor)\n",
    "customLoader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "# customLoader.dataset\n",
    "with torch.no_grad():\n",
    "    for x, y in customLoader:\n",
    "\n",
    "        x = x.unsqueeze(1)  # Adds a channel dimension at position 1\n",
    "        y = y.long()\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        # print(y)\n",
    "        scores = test_model(x)\n",
    "        print(scores)\n",
    "        y = int(y.to(torch.int32))\n",
    "        predictions = torch.argmax(scores, dim=1)\n",
    "        tensor_int = int(predictions.to(torch.int32))\n",
    "        # print(customLoader.)\n",
    "        print(predictions, \"-----\", y)\n",
    "        # print(f\" The true Value is {emotion_class[y]} and predicted class is {emotion_class[tensor_int]}\")\n",
    "        # print(scores)\n",
    "\n",
    "        \n",
    "        # print(predictions)\n",
    "\n",
    "    test_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
